{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3sQoe2Tg_fb"
      },
      "source": [
        "# ðŸ“š Agentic RAG System\n",
        "This project implements an **intelligent research assistant** that retrieves and synthesizes information using:\n",
        "1. **ArXiv papers** as the primary knowledge source (**RAG approach**)\n",
        "2. **Web search (Tavily API)**\n",
        "3. **LangGraph** for orchestrating the decision-making workflow\n",
        "\n",
        "## ðŸŽ¯ Purpose\n",
        "\n",
        "The system is designed to provide research-backed answers to technical and scientific questions by:\n",
        "- Prioritizing academic and research papers from ArXiv for scientific queries\n",
        "- Falling back to web search for recent developments or non-academic topics\n",
        "- Maintaining conversation context for coherent multi-turn interactions\n",
        "- Ensuring proper attribution and citations in responses\n",
        "\n",
        "## ðŸ”‘ Prerequisites\n",
        "\n",
        "To use this system, you'll need:\n",
        "\n",
        "1. **OpenAI API Key**\n",
        "   - Required for:\n",
        "     - Text embeddings (for semantic search)\n",
        "     - Response generation (GPT-4 Turbo)\n",
        "     - Routing decisions (GPT-4o-mini)\n",
        "   - Get it from: [OpenAI Platform](https://platform.openai.com)\n",
        "\n",
        "2. **Tavily API Key**\n",
        "   - Required for:\n",
        "     - Web search fallback functionality\n",
        "     - Real-time information retrieval\n",
        "     - Academic domain filtering\n",
        "   - Get it from: [Tavily](https://app.tavily.com)\n",
        "\n",
        "3. **Python Environment**\n",
        "   - Python 3.8 or higher\n",
        "   - Required packages (will be installed automatically):\n",
        "     - langchain-community\n",
        "     - langchain_chroma\n",
        "     - langchain_core\n",
        "     - langchain_openai\n",
        "     - langchain_text_splitters\n",
        "     - langgraph\n",
        "     - tavily-python\n",
        "     - openai\n",
        "     - python-dotenv\n",
        "\n",
        "\n",
        "## ðŸ¤– Agentic Workflow Architecture\n",
        "\n",
        "The user workflow is translated into an agentic system through the following components:\n",
        "\n",
        "1. **State Management**\n",
        "   - **Conversation State**: Tracks user queries, system responses, and context\n",
        "   - **Search State**: Maintains information about current search results and sources\n",
        "   - **Decision State**: Stores routing decisions and their rationale\n",
        "\n",
        "2. **Agent Components**\n",
        "   - **Router Agent**: Makes decisions about information sources\n",
        "     - Analyzes query type and context\n",
        "     - Determines optimal search strategy\n",
        "     - Handles fallback mechanisms\n",
        "   \n",
        "   - **Search Agent**: Executes information retrieval\n",
        "     - Manages ArXiv API interactions\n",
        "     - Handles Tavily web search\n",
        "     - Processes and filters results\n",
        "   \n",
        "   - **Synthesis Agent**: Combines and formats information\n",
        "     - Merges multiple sources\n",
        "     - Ensures proper attribution\n",
        "     - Generates coherent responses\n",
        "\n",
        "3. **Feedback Loop**\n",
        "   - System learns from user interactions\n",
        "   - Improves routing decisions over time\n",
        "   - Adapts to user preferences and query patterns\n",
        "\n",
        "## ðŸ“Š Data Requirements and Sources\n",
        "\n",
        "The system requires and manages several types of data:\n",
        "\n",
        "1. **Input Data**\n",
        "   - **User Queries**: Natural language questions and follow-ups\n",
        "   - **Conversation History**: Previous interactions for context\n",
        "   - **User Preferences**: Optional settings for search behavior\n",
        "\n",
        "2. **Knowledge Sources**\n",
        "   - **ArXiv Papers**:\n",
        "     - Source: ArXiv API\n",
        "     - Format: PDF documents\n",
        "     - Update Frequency: Daily\n",
        "     - Coverage: Scientific and technical papers\n",
        "   \n",
        "   - **Web Content**:\n",
        "     - Source: Tavily API\n",
        "     - Format: Web pages and documents\n",
        "     - Update Frequency: Real-time\n",
        "     - Coverage: News, blogs, documentation, etc.\n",
        "\n",
        "3. **Processed Data**\n",
        "   - **Embeddings**: Vector representations of text\n",
        "     - Generated using OpenAI's embedding model\n",
        "     - Stored in vector database\n",
        "   \n",
        "   - **Chunks**: Processed text segments\n",
        "     - Size: Optimized for semantic search\n",
        "     - Metadata: Source, date, relevance score\n",
        "   \n",
        "   - **Citations**: Reference information\n",
        "     - Paper titles, authors, URLs\n",
        "     - Web page sources and dates\n",
        "\n",
        "4. **Output Data**\n",
        "   - **Responses**: Generated answers with citations\n",
        "   - **Search Results**: Ranked and filtered information\n",
        "   - **Conversation Logs**: Interaction history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi4l10mgMCY6"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0zyWACuhcfqG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install required packages\n",
        "! pip install -qU langchain langgraph pypdf chromadb tavily-python openai python-dotenv pyboxen langchain-community langchain_chroma langchain_core langchain_openai langchain_text_splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDJAvAUpcjmN"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os  # Provides functions to interact with the operating system.\n",
        "from pyboxen import boxen  # Used to display stylized boxes in the terminal for better CLI UI.\n",
        "from getpass import getpass  # Allows secure password input without echoing.\n",
        "\n",
        "from typing import TypedDict, List, Dict, Optional, Literal, Union, Annotated, cast  # Used for type annotations and static type checking.\n",
        "from langchain_core.documents import Document  # Represents and structures text data in LangChain.\n",
        "from langchain_core.output_parsers import StrOutputParser  # Parses raw LLM output into usable string format.\n",
        "from langchain_community.document_loaders import PyPDFLoader  # Loads and extracts text from PDF documents.\n",
        "\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter  # Splits text into chunks using markdown headers or character limits.\n",
        "\n",
        "from langchain_chroma import Chroma  # Provides integration with Chroma vector store for embedding storage and retrieval.\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # Interfaces with OpenAI for embeddings and chat models.\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate  # Manages prompt templates for chat-based interactions.\n",
        "\n",
        "from langgraph.graph import StateGraph, END  # Helps define state-based logic flows for chat systems.\n",
        "from langchain.memory import ConversationBufferMemory  # Maintains memory of past conversation for context retention.\n",
        "\n",
        "from tavily import TavilyClient  # Interfaces with Tavily for real-time web search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOl5svrxoDkQ"
      },
      "source": [
        "# API Key Submission\n",
        "\n",
        "Please follow the instructions below:\n",
        "\n",
        "1. **Provide the Tavily API Key**\n",
        "2. **Provide the Open API Key**\n",
        "3. **Press Enter** to proceed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y1CrD7yecpRF",
        "outputId": "46b8d2b4-60bb-4e16-dd05-f6415a5ead6a"
      },
      "outputs": [],
      "source": [
        "# Set API keys\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter Tavily API Key (get from https://app.tavily.com): \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVsoCt4BhfRp"
      },
      "source": [
        "## 2. Define State and System Architecture\n",
        "\n",
        "This is important because Agents need context to take decisions and showcase \"Agency\", the state helps us define the information that the agent will require and also capture information through out the whole process.\n",
        "\n",
        "We'll define our system's state and flow using **LangGraph**. The state will track our:\n",
        "- **Input question**\n",
        "- **Retrieved ArXiv results**\n",
        "- **Web search results**\n",
        "- **Final answer**\n",
        "- **Conversation history for context**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DX0VBugddBN"
      },
      "outputs": [],
      "source": [
        "# Define our system state - this is what passes between nodes in our graph\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"State definition for our agentic RAG system\"\"\"\n",
        "    question: str  # User's current question\n",
        "    arxiv_results: Optional[List[Document]]  # Results from ArXiv papers (if any)\n",
        "    web_results: Optional[List[Dict]]  # Results from web search (if any)\n",
        "    answer: str  # Final synthesized answer\n",
        "    conversation_history: str  # Previous Q&A for context\n",
        "    memory: any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym7UTPc4hpli"
      },
      "source": [
        "## 3. Router Node Implementation\n",
        "\n",
        "The **Router Node** is responsible for deciding whether to use **ArXiv papers** or **web search**.\n",
        "- **First**, it tries to use **ArXiv papers** (our local knowledge source).\n",
        "- **Falls back** to **web search** if needed.\n",
        "\n",
        "This demonstrates **strategic decision-making capabilities**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oSbkgqwdh_R"
      },
      "outputs": [],
      "source": [
        "router_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a highly specialized research assistant with access to two information sources:\n",
        "1. A collection of ArXiv research papers\n",
        "2. A web search tool\n",
        "\n",
        "Your task is to determine which source would be better to answer the user's question.\n",
        "FIRST try to use ArXiv papers for scientific and academic questions.\n",
        "ONLY use web search if:\n",
        "- The question requires very recent information not likely in research papers\n",
        "- The question is about general knowledge, news, or non-academic topics\n",
        "- The question asks for information beyond what academic papers would contain\n",
        "\n",
        "Consider the conversation history for context.\n",
        "\n",
        "Question: {question}\n",
        "Conversation History: {conversation_history}\n",
        "\n",
        "Respond with ONLY ONE of these two options:\n",
        "\"arxiv\" - if the question should be answered using research papers\n",
        "\"web\" - if the question requires web search\n",
        "\n",
        "Your decision should be a single word only (either \"arxiv\" or \"web\"). Do not include any explanation, reasoning, or additional text in your response.\n",
        "\"\"\")\n",
        "\n",
        "def router_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Determines whether to use ArXiv papers or web search based on the question.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the question and conversation history\n",
        "\n",
        "    Returns:\n",
        "        Dict indicating which path to take next\n",
        "    \"\"\"\n",
        "    # Use a lighter model for routing decisions\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "    # Create a chain that outputs just the decision text\n",
        "    chain = router_prompt | llm\n",
        "\n",
        "    # Invoke the chain with our question and history\n",
        "    # Get the content of the AIMessage object instead of directly calling strip()\n",
        "    decision = chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"conversation_history\": state[\"conversation_history\"]\n",
        "    }).content.strip().lower()\n",
        "\n",
        "    print(f\"Router decision: {decision}\")\n",
        "\n",
        "    # Return the next node to be called based on the decision\n",
        "    if \"web\" in decision:\n",
        "        return {\"next\": \"web_search\"}\n",
        "    else:\n",
        "        return {\"next\": \"arxiv_retrieval\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D_WGWpKhz4D"
      },
      "source": [
        "# ArXiv Processor Documentation\n",
        "\n",
        "## Overview\n",
        "The `ArXivProcessor` class is designed to handle processing ArXiv PDFs for retrieval-augmented generation (RAG) systems. It implements document-aware chunking strategies specifically optimized for scientific papers.\n",
        "\n",
        "## Key Features\n",
        "- **Two-step chunking strategy**:\n",
        " 1. Markdown header splitting to preserve document structure\n",
        " 2. Recursive character splitting for handling longer sections effectively\n",
        "- **Confidence-based retrieval** with threshold filtering\n",
        "- **Metadata preservation** from original PDFs\n",
        "\n",
        "## Class Structure\n",
        "\n",
        "### Constructor: `__init__()`\n",
        "Initializes the processor with specialized document chunking strategies:\n",
        "- `MarkdownHeaderTextSplitter` to maintain document section structure\n",
        "- `RecursiveCharacterTextSplitter` for detailed content subdivision\n",
        "\n",
        "### Methods\n",
        "\n",
        "#### `load_and_process(pdf_urls: List[str])`\n",
        "Processes ArXiv PDFs with document-aware chunking:\n",
        "- Loads PDFs from provided URLs\n",
        "- Converts content to markdown-style text with headers\n",
        "- Applies two-stage chunking process\n",
        "- Creates a vector store with OpenAI embeddings\n",
        "\n",
        "#### `retrieve(question: str, confidence_threshold: float = 0.75, k: int = 5)`\n",
        "Retrieves relevant chunks with confidence scoring:\n",
        "- Performs similarity search based on user query\n",
        "- Filters results by confidence threshold\n",
        "- Returns only high-relevance document chunks\n",
        "\n",
        "## Implementation Example\n",
        "The documented code includes a sample implementation that loads and processes two ArXiv papers:\n",
        "- Quantum computing paper: https://arxiv.org/pdf/2305.10343.pdf\n",
        "- LLM research paper: https://arxiv.org/pdf/2303.04137.pdf\n",
        "\n",
        "## Dependencies\n",
        "- `PyPDFLoader` for PDF handling\n",
        "- `MarkdownHeaderTextSplitter` and `RecursiveCharacterTextSplitter` for content chunking\n",
        "- `OpenAIEmbeddings` for vector embeddings\n",
        "- `Chroma` for vector storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "QeTPjOKgdom7",
        "outputId": "56c7257b-75fe-4ba7-fe5b-19c09d6d74b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mâ•­â”€\u001b[0m\u001b[36m >>> Initialization \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m                                                        \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m   Initializing ArXiv processor with sample papers...   \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m                                                        \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                         \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> PDF Loading \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m                                                       \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m   Loading PDF from https://arxiv.org/pdf/2504.10412   \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m                                                       \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                          \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Processing Complete \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m                                   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m   Created 35 chunks from 1 PDFs   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m                                   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                              \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Status \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m                                  \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m   ArXiv processor initialized!   \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m                                  \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                               \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class ArXivProcessor:\n",
        "    \"\"\"\n",
        "    Handles processing ArXiv PDFs for retrieval-augmented generation.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the processor with document-aware chunking strategies.\n",
        "\n",
        "        The chunking strategy uses a two-step approach:\n",
        "        1. Markdown header splitting preserves document structure and headers\n",
        "        2. Recursive character splitting handles longer sections effectively\n",
        "        \"\"\"\n",
        "        # Header splitter preserves section structure in scientific papers\n",
        "        self.header_splitter = MarkdownHeaderTextSplitter(\n",
        "            headers_to_split_on=[\n",
        "                (\"#\", \"Section\"),           # Main sections\n",
        "                (\"##\", \"Subsection\"),       # Subsections\n",
        "                (\"###\", \"Subsubsection\")    # Sub-subsections\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Recursive splitter handles nested hierarchies and technical content\n",
        "        # - Chunk size of 1000 balances context vs specificity\n",
        "        # - Overlap of 200 ensures continuity between chunks\n",
        "        # - Separators prioritize natural breaks in scientific text\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "        # Will be initialized when documents are loaded\n",
        "        self.vector_store = None\n",
        "\n",
        "    def load_and_process(self, pdf_urls: List[str]):\n",
        "        \"\"\"\n",
        "        Process ArXiv PDFs with document-aware chunking\n",
        "\n",
        "        Args:\n",
        "            pdf_urls: List of URLs to ArXiv PDFs\n",
        "        \"\"\"\n",
        "        all_chunks = []\n",
        "\n",
        "        # Process each PDF\n",
        "        for url in pdf_urls:\n",
        "            print(boxen(f\"Loading PDF from {url}\", title=\">>> PDF Loading\", color=\"blue\", padding=1))\n",
        "            loader = PyPDFLoader(url)\n",
        "            pages = loader.load()\n",
        "\n",
        "            # Process each page\n",
        "            for page in pages:\n",
        "                # Convert PDF content to markdown-style text with headers\n",
        "                page_text = f\"# {page.metadata['source']}\\n## Page {page.metadata['page']}\\n{page.page_content}\"\n",
        "\n",
        "                # First split by headers to maintain document structure\n",
        "                header_chunks = self.header_splitter.split_text(page_text)\n",
        "\n",
        "                # Then split large sections into smaller chunks\n",
        "                small_chunks = self.text_splitter.split_documents(header_chunks)\n",
        "\n",
        "                # Add to our collection\n",
        "                all_chunks.extend(small_chunks)\n",
        "\n",
        "        print(boxen(f\"Created {len(all_chunks)} chunks from {len(pdf_urls)} PDFs\", title=\">>> Processing Complete\", color=\"green\", padding=1))\n",
        "\n",
        "        # Create vector store with OpenAI embeddings\n",
        "        self.vector_store = Chroma.from_documents(\n",
        "            documents=all_chunks,\n",
        "            embedding=OpenAIEmbeddings(),\n",
        "            persist_directory=\"./arxiv_db\"\n",
        "        )\n",
        "\n",
        "    def retrieve(self, question: str, confidence_threshold: float = 0.75, k: int = 5):\n",
        "        \"\"\"\n",
        "        Retrieve relevant chunks with confidence scoring\n",
        "\n",
        "        Args:\n",
        "            question: User question to find relevant information for\n",
        "            confidence_threshold: Minimum relevance score (0-1) to include a result\n",
        "            k: Maximum number of results to return\n",
        "\n",
        "        Returns:\n",
        "            List of relevant document chunks that meet the threshold\n",
        "        \"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No ArXiv documents loaded. Run load_and_process first.\")\n",
        "\n",
        "        # Perform similarity search with relevance scores\n",
        "        results = self.vector_store.similarity_search_with_relevance_scores(\n",
        "            question, k=k\n",
        "        )\n",
        "\n",
        "        # Filter by confidence threshold\n",
        "        filtered_results = [doc for doc, score in results if score >= confidence_threshold]\n",
        "\n",
        "        print(boxen(f\"Found {len(filtered_results)} relevant chunks above threshold {confidence_threshold}\", title=\">>> Context\", color=\"yellow\", padding=1))\n",
        "\n",
        "        return filtered_results\n",
        "\n",
        "# Load sample ArXiv PDFs\n",
        "print(boxen(\"Initializing ArXiv processor with sample papers...\", title=\">>> Initialization\", color=\"cyan\", padding=1))\n",
        "arxiv_processor = ArXivProcessor()\n",
        "arxiv_processor.load_and_process([\n",
        "    \"https://arxiv.org/pdf/2504.10412\"   # LLM research paper\n",
        "])\n",
        "print(boxen(\"ArXiv processor initialized!\", title=\">>> Status\", color=\"green\", padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeaD77BupxMv"
      },
      "source": [
        "# ArXiv Retrieval Node Documentation\n",
        "\n",
        "## Overview\n",
        "The `arxiv_retrieval_node` function serves as a retrieval component in an agent-based system, fetching relevant scientific information from ArXiv papers based on user queries.\n",
        "\n",
        "## Function Signature\n",
        "`arxiv_retrieval_node(state: AgentState) -> dict`\n",
        "\n",
        "## Parameters\n",
        "- `state`: An AgentState object containing the current conversation state, including:\n",
        " - `question`: The user's query to search for in ArXiv papers\n",
        "\n",
        "## Functionality\n",
        "The function:\n",
        "1. Extracts the user's question from the input state\n",
        "2. Calls the `arxiv_processor.retrieve()` method to find relevant document chunks\n",
        "3. Uses a reduced confidence threshold (0.5) compared to the default (0.75) to improve recall\n",
        "4. Returns the retrieved documents for further processing\n",
        "\n",
        "## Return Value\n",
        "Returns a dictionary with:\n",
        "- `arxiv_results`: A list of document chunks from ArXiv papers relevant to the user's question\n",
        "\n",
        "## Integration Notes\n",
        "- This function is designed to be used as a node in an agent workflow\n",
        "- The reduced confidence threshold ensures more potential matches are returned, prioritizing recall over precision\n",
        "- The retrieved documents can be used by subsequent nodes for answering the user's question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QI0RXSbdvCv"
      },
      "outputs": [],
      "source": [
        "def arxiv_retrieval_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Retrieves relevant information from ArXiv papers based on the question.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the question\n",
        "\n",
        "    Returns:\n",
        "        Updated state with arxiv_results\n",
        "    \"\"\"\n",
        "    # Retrieve relevant documents from ArXiv\n",
        "    relevant_docs = arxiv_processor.retrieve(\n",
        "        question=state[\"question\"],\n",
        "        confidence_threshold=0.5  # Adjusted threshold for better recall\n",
        "    )\n",
        "\n",
        "    # Check if we found enough relevant content\n",
        "    return {\"arxiv_results\": relevant_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SqO1XREiD7z"
      },
      "source": [
        "## 5. Web Search Node Implementation\n",
        "\n",
        "The **Web Search Node** uses the **Tavily API** to search the web when **ArXiv papers** don't have the answer.\n",
        "\n",
        "- **Optimizes** the search query\n",
        "- **Filters and processes** results\n",
        "- **Ensures** proper attribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WsFmnmpd3CI"
      },
      "outputs": [],
      "source": [
        "web_searcher = TavilyClient()\n",
        "def web_search_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Searches the web for information using the Tavily API.\n",
        "    \"\"\"\n",
        "    # Include academic domains to improve search quality\n",
        "    academic_domains = [\"arxiv.org\", \"scholar.google.com\", \"researchgate.net\", \"edu\"]\n",
        "\n",
        "    # Get search results with answer\n",
        "    search_response = web_searcher.search(\n",
        "        query=state[\"question\"],\n",
        "        max_results=5,\n",
        "        include_domains=academic_domains,\n",
        "        search_depth=\"advanced\",  # Use advanced search for better results\n",
        "        include_answer=True  # Request direct answer\n",
        "    )\n",
        "\n",
        "    # If we have a direct answer, use it\n",
        "    if search_response.get(\"answer\"):\n",
        "        return {\n",
        "            \"web_results\": search_response.get(\"results\", []),\n",
        "            \"direct_answer\": search_response[\"answer\"]\n",
        "        }\n",
        "\n",
        "    return {\"web_results\": search_response.get(\"results\", [])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYoo-tCciKHn"
      },
      "source": [
        "# Function Documentation: `synthesize_answer_node`\n",
        "\n",
        "## Overview\n",
        "The `synthesize_answer_node` function is a key component in a LangChain-based conversational agent. It is responsible for generating a comprehensive answer based on either scientific research papers (from ArXiv) or web search results (via Tavily). The generated response is contextual, well-structured, and strictly grounded in the retrieved data.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "To synthesize a high-quality, structured, and citation-backed answer from the information retrieved during the conversational flow â€” either from ArXiv research papers or real-time web search results.\n",
        "\n",
        "---\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- **state (AgentState)**:  \n",
        "  A dictionary representing the current state of the agent, which includes:\n",
        "  - `question`: The user's query.\n",
        "  - `arxiv_results`: A list of research paper excerpts (if available).\n",
        "  - `web_results`: A list of web search results (used when no ArXiv data is present).\n",
        "  - `conversation_history`: Context from previous exchanges to maintain continuity.\n",
        "\n",
        "---\n",
        "\n",
        "## Logic Flow\n",
        "\n",
        "1. **Source Determination**:  \n",
        "   The function first checks whether ArXiv results are available. If so, it uses them; otherwise, it falls back to web search results.\n",
        "\n",
        "2. **Prompt Construction**:  \n",
        "   A custom `prompt_template` is built depending on the data source. Each template includes:\n",
        "   - The original question.\n",
        "   - Retrieved content (formatted accordingly).\n",
        "   - Prior conversation context.\n",
        "   - Explicit instructions to ensure grounded, factual, and well-structured responses.\n",
        "\n",
        "3. **Model Invocation**:  \n",
        "   - Uses `ChatOpenAI` (specifically `gpt-4o-mini`) for advanced reasoning and response generation.\n",
        "   - Combines the prompt and model into a LangChain chain using `ChatPromptTemplate` and `StrOutputParser`.\n",
        "\n",
        "4. **Response Handling**:  \n",
        "   - If web results were used, the function appends a list of source URLs at the end of the response.\n",
        "   - If ArXiv sources were used, inline citations in the format `(Author et al., Page X)` are expected.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "\n",
        "- Returns a dictionary with a single key:  \n",
        "  - `answer`: A fully formatted, cited response derived from either research papers or search results.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Characteristics\n",
        "\n",
        "- **Grounded Output**: The model is instructed not to hallucinate or invent facts.\n",
        "- **Citations Included**: Adds credibility and traceability via inline citations or URL references.\n",
        "- **Context-Aware**: Maintains conversation context to provide coherent multi-turn interactions.\n",
        "- **Readable Format**: Uses markdown elements such as headers, bullet points, and bold text for readability.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h2iGpE9d8VM"
      },
      "outputs": [],
      "source": [
        "def synthesize_answer_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Synthesizes a comprehensive answer from retrieved information.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing question and retrieved information\n",
        "\n",
        "    Returns:\n",
        "        Updated state with answer\n",
        "    \"\"\"\n",
        "    # If we have a direct answer from web search, use it\n",
        "    if state.get(\"direct_answer\"):\n",
        "        answer_content = state[\"direct_answer\"]\n",
        "        source_type = \"Web Search Results\"\n",
        "    else:\n",
        "        # Determine which source to use for synthesis\n",
        "        if state[\"arxiv_results\"] and len(state[\"arxiv_results\"]) > 0:\n",
        "            # Using ArXiv research papers\n",
        "            sources = \"\\n\\n\".join([\n",
        "                f\"--- Document: {d.metadata.get('source', 'Unknown')} (Page {d.metadata.get('page', 'Unknown')}) ---\\n{d.page_content}\"\n",
        "                for d in state[\"arxiv_results\"]\n",
        "            ])\n",
        "            displayed_sources = sources\n",
        "            source_type = \"ArXiv Papers\"\n",
        "\n",
        "            prompt_template = \"\"\"\n",
        "            You are a knowledgeable research assistant specializing in mathematical theory and scientific literature analysis.\n",
        "\n",
        "            Your goal is to generate clean, formatted responses to user questions based solely on the provided ArXiv sources.\n",
        "\n",
        "            ---\n",
        "\n",
        "            Question:\n",
        "            {question}\n",
        "\n",
        "            Relevant Extracts from ArXiv Papers:\n",
        "            {sources}\n",
        "\n",
        "            Conversation History:\n",
        "            {conversation_history}\n",
        "\n",
        "            ---\n",
        "\n",
        "            Instructions for Synthesizing the Answer:\n",
        "\n",
        "            1. Read the extracts thoroughly and understand the concepts.\n",
        "            2. Answer the question comprehensively using only the provided context.\n",
        "            3. Organize the response into the following markdown sections (if applicable):\n",
        "              - Summary\n",
        "              - Key Concepts\n",
        "              - Theoretical Results\n",
        "              - Implications / Applications\n",
        "            4. Cite from the paper in the format: (Author et al., Page X). If page number is unknown, write: (Author et al.).\n",
        "            6. Avoid repetition, excessive formal tone, or generic commentary. Be clear and concise.**\n",
        "            7. If the provided text lacks enough detail to answer, state it clearly and suggest what additional info is needed.\n",
        "\n",
        "            ---\n",
        "\n",
        "            Now, write a well-structured, markdown-formatted answer to the question and it should be in a readable format as well.\n",
        "            \"\"\"\n",
        "        else:\n",
        "            # Using web search results\n",
        "            sources = \"\\n\\n\".join([\n",
        "                f\"--- Source {i+1}: {res['title']} ---\\n{res['content']}\"\n",
        "                for i, res in enumerate(state[\"web_results\"] or [])\n",
        "            ])\n",
        "            displayed_sources = sources\n",
        "            source_type = \"Web Search Results\"\n",
        "\n",
        "            prompt_template = \"\"\"\n",
        "            You are a knowledgeable research assistant providing accurate information based on web search results.\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Here are relevant web search results:\n",
        "            {sources}\n",
        "\n",
        "            Conversation History:\n",
        "            {conversation_history}\n",
        "\n",
        "            Instructions:\n",
        "            1. Synthesize a comprehensive answer using ONLY the information provided above.\n",
        "            2. Cite sources using [1], [2], etc. corresponding to the source numbers above.\n",
        "            3. If the search results don't contain sufficient information, acknowledge the limitations.\n",
        "            4. DO NOT make up information not present in the sources.\n",
        "            5. Include only facts supported by the sources.\n",
        "\n",
        "            Your answer:\n",
        "            \"\"\"\n",
        "\n",
        "        # Print retrieval information\n",
        "        print(f\"\\n=== Retrieved chunks from {source_type} ===\")\n",
        "        print(displayed_sources)\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Create the prompt\n",
        "        synthesis_prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "\n",
        "        # Use a more capable model for synthesis\n",
        "        llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "        chain = synthesis_prompt | llm | StrOutputParser()\n",
        "\n",
        "        # Generate the answer\n",
        "        response = chain.invoke({\n",
        "            \"question\": state[\"question\"],\n",
        "            \"sources\": sources,\n",
        "            \"conversation_history\": state[\"conversation_history\"]\n",
        "        })\n",
        "\n",
        "        # Add source citations for web results\n",
        "        if state.get(\"web_results\") and not state.get(\"arxiv_results\"):\n",
        "            answer_content = response\n",
        "\n",
        "            # Add URL references at the end\n",
        "            url_citations = \"\\n\\nSources:\\n\" + \"\\n\".join([\n",
        "                f\"[{i+1}] {res['url']}\"\n",
        "                for i, res in enumerate(state[\"web_results\"] or [])\n",
        "            ])\n",
        "\n",
        "            answer_content += url_citations\n",
        "        else:\n",
        "            answer_content = response\n",
        "\n",
        "    # Using markdown and plain text for better readability\n",
        "    formatted_output = f\"\"\"\n",
        "## Context\n",
        "**Question:** {state[\"question\"]}\n",
        "**Source:** {source_type}\n",
        "\n",
        "## Response\n",
        "{answer_content}\n",
        "\"\"\"\n",
        "\n",
        "    return {\"answer\": formatted_output}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePSZSMQBiaMC"
      },
      "source": [
        "## 7. Conversation Memory Node\n",
        "\n",
        "This node **manages conversation history** to provide context for **multi-turn interactions**.\n",
        "\n",
        "- **Stores** previous Q&A\n",
        "- **Updates** the state with the current interaction\n",
        "- **Maintains** a sliding window of relevant history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgefbaa_eAfZ"
      },
      "outputs": [],
      "source": [
        "# Initialize conversation memory\n",
        "\n",
        "def update_memory_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Updates the conversation memory with the current Q&A pair.\n",
        "\n",
        "    Args:\n",
        "        state: Current state with question and answer\n",
        "\n",
        "    Returns:\n",
        "        Updated state with new conversation_history\n",
        "    \"\"\"\n",
        "    # Save the current interaction to memory\n",
        "    memory = state['memory']\n",
        "    memory.save_context(\n",
        "        {\"question\": state[\"question\"]},\n",
        "        {\"answer\": state[\"answer\"]}\n",
        "    )\n",
        "\n",
        "    # Return the updated state\n",
        "    return {\"conversation_history\": memory.load_memory_variables({}).get(\"history\", \"\")}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxKEeu64iglN"
      },
      "source": [
        "# Workflow State Graph Setup\n",
        "\n",
        "## Overview\n",
        "This section sets up the **LangGraph state machine** for managing the conversational agentâ€™s workflow. It defines how user queries are processed step-by-step using modular nodes.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "To create a graph-based control flow that determines how the agent processes input, performs retrieval, synthesizes responses, updates memory, and eventually ends the workflow.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Components\n",
        "\n",
        "### 1. **Workflow Initialization**\n",
        "- A new `StateGraph` is initialized with the `AgentState` type, defining the structure of the workflow.\n",
        "\n",
        "### 2. **Node Definitions**\n",
        "The graph is composed of several functional nodes, each responsible for a specific task:\n",
        "- **router**: Determines whether to fetch data from the web or ArXiv.\n",
        "- **arxiv_retrieval**: Retrieves relevant research papers from ArXiv.\n",
        "- **web_search**: Retrieves web results via Tavily.\n",
        "- **synthesize**: Synthesizes a final answer from the retrieved information.\n",
        "- **update_memory**: Stores the interaction context for future turns.\n",
        "\n",
        "### 3. **Entry Point**\n",
        "- The `router` node is set as the initial entry point for the graph, meaning every workflow starts with routing logic.\n",
        "\n",
        "### 4. **Conditional Routing**\n",
        "- A conditional edge is established from `router` based on the `\"next\"` field in the state:\n",
        "  - If `\"next\"` is `\"web_search\"`, it routes to the `web_search` node.\n",
        "  - If `\"next\"` is `\"arxiv_retrieval\"`, it routes to the `arxiv_retrieval` node.\n",
        "\n",
        "### 5. **Workflow Sequence**\n",
        "The following fixed transitions define the remainder of the workflow:\n",
        "- From either `web_search` or `arxiv_retrieval` â†’ go to `synthesize`\n",
        "- From `synthesize` â†’ go to `update_memory`\n",
        "- From `update_memory` â†’ reach `END` (completion of the flow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRYbjFhHeEZt"
      },
      "outputs": [],
      "source": [
        "# Create the workflow state graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add all nodes to the graph\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"arxiv_retrieval\", arxiv_retrieval_node)\n",
        "workflow.add_node(\"web_search\", web_search_node)\n",
        "workflow.add_node(\"synthesize\", synthesize_answer_node)\n",
        "workflow.add_node(\"update_memory\", update_memory_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "# Define conditional edges from router\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    lambda state: state[\"next\"],\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"arxiv_retrieval\": \"arxiv_retrieval\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define rest of the edges\n",
        "workflow.add_edge(\"arxiv_retrieval\", \"synthesize\")\n",
        "workflow.add_edge(\"web_search\", \"synthesize\")\n",
        "workflow.add_edge(\"synthesize\", \"update_memory\")\n",
        "workflow.add_edge(\"update_memory\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "3pkhue9nKX3A",
        "outputId": "c7a347b3-d22e-4991-dc31-1b8d283e266b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m4TP3xSioHc"
      },
      "source": [
        "## 9. Testing the System\n",
        "\n",
        "Let's **test our system** with different types of questions:\n",
        "\n",
        "- **Questions answerable** from ArXiv papers\n",
        "- **Questions requiring** web search\n",
        "- **Follow-up questions** to test memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgjgGd6EJOJO",
        "outputId": "a002fe3e-5370-4674-bfdd-068d568bbf0b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-f1712b8132d2>:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(return_messages=False, output_key=\"answer\", input_key=\"question\")\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(return_messages=False, output_key=\"answer\", input_key=\"question\")\n",
        "initial_state = {\n",
        "    \"question\": None,\n",
        "    \"arxiv_results\": None,\n",
        "    \"web_results\": None,\n",
        "    \"answer\": \"\",\n",
        "    \"conversation_history\": memory.load_memory_variables({}).get(\"history\", \"\"),\n",
        "    \"memory\": memory\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFoxsXLWeHSv"
      },
      "outputs": [],
      "source": [
        "def ask(app, question: str, state: AgentState):\n",
        "    \"\"\"\n",
        "    Ask a question to the agentic RAG system.\n",
        "\n",
        "    Args:\n",
        "        question: User's question\n",
        "\n",
        "    Returns:\n",
        "        The system's answer\n",
        "    \"\"\"\n",
        "    # Initialize the state\n",
        "\n",
        "    # Invoke the workflow\n",
        "    state['question'] = question\n",
        "    result = app.invoke(state)\n",
        "    # Print the response details with pyboxen\n",
        "    print(boxen(f\"Question: {result['question']}\", title=\">>> Question\", color=\"blue\", padding=1))\n",
        "\n",
        "    if result[\"arxiv_results\"]:\n",
        "        arxiv_count = len(result[\"arxiv_results\"])\n",
        "        print(boxen(f\"Found {arxiv_count} ArXiv results\", title=\">>> ArXiv Results\", color=\"magenta\", padding=1))\n",
        "    elif result[\"web_results\"]:\n",
        "        web_count = len(result[\"web_results\"])\n",
        "        print(boxen(f\"Found {web_count} Web results\", title=\">>> Web Results\", color=\"magenta\", padding=1))\n",
        "    else:\n",
        "        print(boxen(\"No results found\", title=\">>> Results\", color=\"red\", padding=1))\n",
        "\n",
        "    print(boxen(result[\"answer\"], title=\">>> Answer\", color=\"green\", padding=1))\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b0Ps7Nw1exMl",
        "outputId": "5c4f1559-6c79-4882-873a-53d4a177225a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Router decision: arxiv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mâ•­â”€\u001b[0m\u001b[33m >>> Context \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m   Found 5 relevant chunks above threshold 0.5   \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                \n",
            "\n",
            "\n",
            "=== Retrieved chunks from ArXiv Papers ===\n",
            "--- Document: Unknown (Page Unknown) ---\n",
            "a scalable, AI-driven path to cleaner codebases, vital for\n",
            "software engineeringâ€™s future.  \n",
            "Index Termsâ€” Graph Neural Networks, Code\n",
            "Refactoring, Software Maintainability, Abstract Syntax\n",
            "Trees, Machine Learning, Cyclomatic Complexity, Code\n",
            "Coupling, Software Engineering.\n",
            "I. INTRODUCTION\n",
            "Software refactoringâ€”the art of tweaking code to make it\n",
            "cleaner, more readable, and easier to maintain without changing\n",
            "its behaviors at the heart of modern software engineering.\n",
            "Picture a sprawling codebase: functions tangled in loops,\n",
            "variables sprawling across modules, and complexity creeping\n",
            "up like vines. Developers spend 30% of their time wrestling\n",
            "with such messes, according to a 2023 GitHub survey [1]. The\n",
            "stakes are highâ€”poor maintainability spikes bugs by 25% and\n",
            "slows feature rollouts by 40% [2]. Traditional tools like\n",
            "SonarQube or Check style flag issues (e.g., methods with 20+\n",
            "lines), but their rigid rules miss the forest for the trees. Enter\n",
            "\n",
            "--- Document: Unknown (Page Unknown) ---\n",
            "peek ahead (real-time refactoring bots). Bar charts compare\n",
            "precision, tables list metrics, and AST graphs show GNN\n",
            "magic. It is a step toward codebases that do not fight back.\n",
            "II. THEORETICAL BACKGROUND\n",
            "Code refactoring is not newâ€”Fowlerâ€™s 1999 book codified it:\n",
            "extract methods, reduce duplication, tame complexity [8].\n",
            "Maintainability hinges on metrics: cyclomatic complexity\n",
            "(paths through codeâ€”10â€™s a red flag), coupling (module\n",
            "dependenciesâ€”5+ screams trouble), and cohesion (how tight a\n",
            "moduleâ€™s purpose is) [9]. High complexityâ€”like a 50-path\n",
            "functionâ€”means bugs hide easier; tight couplingâ€”like twenty\n",
            "cross-module callsâ€”means changes ripple hard. ASTs\n",
            "formalize this. A Python line, if x > 0: y = x, becomes a tree:\n",
            "AI-Driven Code Refactoring: Using Graph Neural Networks to Enhance\n",
            "Software Maintainability\n",
            "Gopichand Bandarupalli1\n",
            "1ai.ml.research.articles@gmail.com\n",
            "1Professional M.B.A., Campbellsville university, Texas, USA\n",
            "\n",
            "--- Document: Unknown (Page Unknown) ---\n",
            "slows feature rollouts by 40% [2]. Traditional tools like\n",
            "SonarQube or Check style flag issues (e.g., methods with 20+\n",
            "lines), but their rigid rules miss the forest for the trees. Enter\n",
            "artificial intelligence (AI), where machine learning (ML)\n",
            "promises to spot patterns humans and static analyzers overlook.\n",
            "This study dives into Graph Neural Networks (GNNs), a\n",
            "cutting-edge ML flavor, to see if they can outsmart these old-\n",
            "school approaches in refactoring code.\n",
            "Why GNNs Code is not just textâ€”it is a structure. Abstract\n",
            "Syntax Trees (ASTs) turn code into graphs: nodes for functions,\n",
            "edges for calls, loops as cycles. GNNs thrive on graphs,\n",
            "learning relationshipsâ€”like how a nested loop jacks up\n",
            "complexity or a global variable ties modules in knots [3].\n",
            "Traditional ML, say decision trees, flattens code into feature\n",
            "lists (e.g., line count, variable count), losing that structural\n",
            "juice. Rule-based tools They are stuck on hardcoded\n",
            "thresholdsâ€”cyclomatic complexity over 10, bad; under, good.\n",
            "\n",
            "--- Document: Unknown (Page Unknown) ---\n",
            "complexity (aiming below 10), coupling (targeting <5\n",
            "dependencies), and refactoring precision (correct suggestions\n",
            "out of 1000). Tools like PyTorch Geometric and Tree-sitter\n",
            "parse ASTs, while PMD tracks metrics [5]. Expect deep dives\n",
            "into preprocessing (50% of files had syntax errors), GNN\n",
            "tuning (80% validation accuracy), and results (92% GNN\n",
            "precision vs. 78% SonarQube).Why care Software eats the\n",
            "worldâ€”$4.5 trillion in 2025 spending [6]and maintainability is\n",
            "its lifeline. A 2022 study found 60% of developers want AI to\n",
            "automate refactoring [7]. This research delivers: a GNN\n",
            "pipeline that learns from codeâ€™s bones, not just its skin,\n",
            "promising faster, smarter fixes. Sections unpack theory (ASTs,\n",
            "GNNs), past work (static vs. ML tools), methods (data\n",
            "wrangling, model specs), experiments (graphs galore), and a\n",
            "peek ahead (real-time refactoring bots). Bar charts compare\n",
            "precision, tables list metrics, and AST graphs show GNN\n",
            "magic. It is a step toward codebases that do not fight back.\n",
            "\n",
            "--- Document: Unknown (Page Unknown) ---\n",
            "1  \n",
            "Abstractâ€” This study dives into Graph Neural Networks\n",
            "(GNNs) as a game-changer for code refactoring, leveraging\n",
            "abstract syntax trees (ASTs) to enhance software\n",
            "maintainability. By analyzing a massive datasetâ€”2 million\n",
            "snippets from CodeSearchNet and a custom 75,000-file\n",
            "GitHub Python corpusâ€”it pits GNNs against rule-based\n",
            "SonarQube and traditional decision trees. Metrics like\n",
            "cyclomatic complexity (target <10), coupling (aim <5), and\n",
            "refactoring precision (correct suggestions) drive the\n",
            "comparison. GNNs hit 92% accuracy, slashing complexity\n",
            "by 35% and coupling by 33%, outpacing SonarQube (78%,\n",
            "16%) and decision trees (85%, 25%). Detailed\n",
            "preprocessing tackled 60% syntax errors, while bar graphs,\n",
            "tables, and AST visuals unpack the results. This work offers\n",
            "a scalable, AI-driven path to cleaner codebases, vital for\n",
            "software engineeringâ€™s future.  \n",
            "Index Termsâ€” Graph Neural Networks, Code\n",
            "Refactoring, Software Maintainability, Abstract Syntax\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> Question \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                                     \n",
            "\u001b[34mâ”‚\u001b[0m                                            \u001b[34mâ”‚\u001b[0m                                                                     \n",
            "\u001b[34mâ”‚\u001b[0m   Question: Explain Software Refactoring   \u001b[34mâ”‚\u001b[0m                                                                     \n",
            "\u001b[34mâ”‚\u001b[0m                                            \u001b[34mâ”‚\u001b[0m                                                                     \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                     \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[35mâ•­â”€\u001b[0m\u001b[35m >>> ArXiv Results \u001b[0m\u001b[35mâ”€â”€â”€â”€â”€â”€\u001b[0m\u001b[35mâ”€â•®\u001b[0m                                                                                      \n",
            "\u001b[35mâ”‚\u001b[0m                           \u001b[35mâ”‚\u001b[0m                                                                                      \n",
            "\u001b[35mâ”‚\u001b[0m   Found 5 ArXiv results   \u001b[35mâ”‚\u001b[0m                                                                                      \n",
            "\u001b[35mâ”‚\u001b[0m                           \u001b[35mâ”‚\u001b[0m                                                                                      \n",
            "\u001b[35mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                                      \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Answer \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Context                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   **Question:** Explain Software Refactoring                                                                    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   **Source:** ArXiv Papers                                                                                      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Response                                                                                                   \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   # Software Refactoring                                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Summary                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   Software refactoring is the process of enhancing code quality without altering its external behavior,         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ultimately contributing to cleaner, more maintainable codebases. It addresses issues such as complexity,      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   readability, and overall maintainability, which are critical aspects of modern software engineering.          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Key Concepts                                                                                               \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   1. **Definition**: Refactoring involves making small tweaks to a codebase to improve clarity and              \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   organization while ensuring no behavioral changes occur (Bandarupalli).                                       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   2. **Importance**: According to a 2023 survey, developers spend about 30% of their time dealing with          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   complex and poorly structured code, leading to increased bugs and slowed feature development                  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   (Bandarupalli).                                                                                               \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   3. **Metrics**:                                                                                               \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m      - **Cyclomatic Complexity**: Measures paths through the code; values above 10 are often worrisome.         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m      - **Coupling**: Refers to the dependencies between modules; values higher than 5 indicate potential        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   trouble.                                                                                                      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m      - **Cohesion**: Describes how closely related and focused the responsibilities of a module are             \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   (Bandarupalli).                                                                                               \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Theoretical Results                                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   Recent studies involve applying Graph Neural Networks (GNNs) in the realm of code refactoring, utilizing      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   Abstract Syntax Trees (ASTs) to analyze code structure more effectively than traditional methods. GNNs        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   achieved a precision of 92% in refactoring suggestions, showing significant improvements over conventional    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   tools like SonarQube, which had a precision of 78% (Bandarupalli).                                            \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   ## Implications / Applications                                                                                \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   The advancement of AI-driven approaches, particularly through machine learning techniques like GNNs,          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   promises to streamline refactoring tasks. This research indicates a shift in the landscape of software        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   engineering towards more automated refactoring solutions, addressing maintainability challenges more          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   effectively (Bandarupalli). The tools developed can potentially reduce cyclomatic complexity by 35% and       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   coupling by 33%, showcasing GNNs as a viable solution for cleaner code management in increasingly complex     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   codebases (Bandarupalli).                                                                                     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   By improving maintainability, software engineering can better accommodate the growing demand for software     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m   features and reduce the incidence of bugs, thus enhancing overall productivity and software quality.          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test with a question about quantum computing (should use ArXiv)\n",
        "updated_state = ask(app, \"Explain Software Refactoring\", initial_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TtHrxeMo1mr"
      },
      "source": [
        "## ðŸŽ“ Conclusion\n",
        "\n",
        "The Agentic RAG System with ArXiv + Web Fallback represents a powerful approach to information retrieval and synthesis, combining the best of both academic and real-time knowledge sources. By intelligently routing queries and maintaining conversation context, it provides:\n",
        "\n",
        "- **Comprehensive Answers**: Leveraging both academic papers and current web information\n",
        "- **Proper Attribution**: Ensuring all sources are properly cited\n",
        "- **Contextual Understanding**: Maintaining conversation history for coherent interactions\n",
        "- **Flexible Knowledge Access**: Adapting to different types of queries and information needs\n",
        "\n",
        "This system is particularly valuable for:\n",
        "- Researchers seeking both theoretical foundations and practical applications\n",
        "- Developers looking for up-to-date technical information\n",
        "- Students and professionals needing comprehensive, well-sourced answers\n",
        "- Anyone requiring a balance between academic rigor and current information\n",
        "\n",
        "The modular architecture and use of LangGraph make it easy to extend and adapt the system for specific use cases or additional knowledge sources."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
